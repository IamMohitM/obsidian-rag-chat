{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "import logging\n",
    "import sys\n",
    "\n",
    "\n",
    "\n",
    "from llama_index.core import SimpleDirectoryReader, VectorStoreIndex\n",
    "\n",
    "from llama_index.llms.azure_openai import AzureOpenAI\n",
    "from llama_index.embeddings.azure_openai import AzureOpenAIEmbedding\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "logging.basicConfig(stream=sys.stdout, level=logging.INFO)\n",
    "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "api_key = os.environ.get(\"AZURE_OPENAI_API_KEY\")\n",
    "azure_endpoint = os.environ.get(\"AZURE_OPENAI_ENDPOINT\")\n",
    "api_version = os.environ.get(\"AZURE_OPENAI_API_VERSION\")\n",
    "model_name = os.environ.get('AZURE_OPENAI_MODEL')\n",
    "embed_model_name = 'text-embedding-3-small'\n",
    "deployment_name = os.environ.get('AZURE_OPENAI_DEPLOYMENT_NAME')\n",
    "\n",
    "llm = AzureOpenAI(\n",
    "    model=model_name,\n",
    "    deployment_name=deployment_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n",
    "\n",
    "# You need to deploy your own embedding model as well as your own chat completion model\n",
    "embed_model = AzureOpenAIEmbedding(\n",
    "    model=embed_model_name,\n",
    "    deployment_name=embed_model_name,\n",
    "    api_key=api_key,\n",
    "    azure_endpoint=azure_endpoint,\n",
    "    api_version=api_version,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "Settings.llm = llm\n",
    "Settings.embed_model = embed_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "documents = SimpleDirectoryReader('data', required_exts='.txt').load_data()\n",
    "index = VectorStoreIndex.from_documents(documents)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "Growing up, the author focused on writing and programming. They wrote short stories, which they later reflected on as lacking in plot but rich in character emotions. Their programming experience began with the IBM 1401 at school, where they learned to write programs using punch cards. Eventually, they transitioned to working with microcomputers, starting with a TRS-80, where they created simple games and a word processor. Despite enjoying programming, the author initially planned to study philosophy in college before ultimately shifting their focus to artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Storage - Saving you Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os.path\n",
    "from llama_index.core import (\n",
    "    StorageContext,\n",
    "    load_index_from_storage,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n"
     ]
    }
   ],
   "source": [
    "PERSIST_DIR = \".data/storage\"\n",
    "if not os.path.exists(PERSIST_DIR):\n",
    "    # load the documents and create the index\n",
    "    documents = SimpleDirectoryReader(\"data\").load_data()\n",
    "    index = VectorStoreIndex.from_documents(documents)\n",
    "    # store it for later\n",
    "    index.storage_context.persist(persist_dir=PERSIST_DIR)\n",
    "    \n",
    "else:\n",
    "    # load the existing index\n",
    "    storage_context = StorageContext.from_defaults(persist_dir=PERSIST_DIR)\n",
    "    index = load_index_from_storage(storage_context)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/text-embedding-3-small/embeddings?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "INFO:httpx:HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "HTTP Request: POST https://content-genai.openai.azure.com/openai/deployments/gpt-4o-mini/chat/completions?api-version=2024-05-01-preview \"HTTP/1.1 200 OK\"\n",
      "Growing up, the author focused on writing and programming. They wrote short stories, which they later reflected on as lacking in plot but rich in character emotions. Their programming experience began with the IBM 1401 at school, where they learned to write programs using punch cards. Eventually, they transitioned to working with microcomputers, starting with a TRS-80, where they created simple games and a word processor. Despite enjoying programming, the author initially planned to study philosophy in college before eventually switching to artificial intelligence.\n"
     ]
    }
   ],
   "source": [
    "query_engine = index.as_query_engine()\n",
    "response = query_engine.query(\"What did the author do growing up?\")\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
